#!/usr/bin/env python3
"""
å¿«é€Ÿè®­ç»ƒæµ‹è¯•è„šæœ¬ - éªŒè¯ä¼˜åŒ–åçš„æ€§èƒ½
"""

import sys
import time
from pathlib import Path

# Add project to path
sys.path.insert(0, str(Path(__file__).parent))

def test_data_loading_speed():
    """æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦"""
    from InstrumentTimbre.core.data.fast_dataset import FastAudioDataset
    from InstrumentTimbre.core.features.fast import FastFeatureExtractor
    
    print("ğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦...")
    
    # åˆå§‹åŒ–å¿«é€Ÿç‰¹å¾æå–å™¨
    extractor = FastFeatureExtractor()
    
    # åˆ›å»ºæ•°æ®é›†ï¼ˆç¬¬ä¸€æ¬¡ä¼šè®¡ç®—ç‰¹å¾å¹¶ç¼“å­˜ï¼‰
    start_time = time.time()
    dataset = FastAudioDataset(
        data_dir='./data/clips',
        feature_extractor=extractor
    )
    setup_time = time.time() - start_time
    
    print(f"æ•°æ®é›†è®¾ç½®æ—¶é—´: {setup_time:.2f}ç§’")
    print(f"æ€»æ ·æœ¬æ•°: {len(dataset)}")
    print(f"ç±»åˆ«æ•°: {len(dataset.class_names)}")
    print(f"ç±»åˆ«: {dataset.class_names}")
    print(f"ç‰¹å¾ç»´åº¦: {dataset.get_feature_dim()}")
    
    # æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦
    print("\næµ‹è¯•æ‰¹é‡åŠ è½½é€Ÿåº¦...")
    from torch.utils.data import DataLoader
    
    loader = DataLoader(dataset, batch_size=32, shuffle=True)
    
    start_time = time.time()
    for i, (features, labels) in enumerate(loader):
        if i >= 10:  # åªæµ‹è¯•å‰10ä¸ªbatch
            break
        if i == 0:
            print(f"Batch shape: {features.shape}, Labels shape: {labels.shape}")
    
    load_time = time.time() - start_time
    samples_processed = min(10 * 32, len(dataset))
    
    print(f"å¤„ç† {samples_processed} æ ·æœ¬ç”¨æ—¶: {load_time:.3f}ç§’")
    print(f"å¹³å‡é€Ÿåº¦: {samples_processed/load_time:.1f} æ ·æœ¬/ç§’")
    
    return dataset

if __name__ == '__main__':
    print("ğŸš€ InstrumentTimbre ä¼˜åŒ–åæ€§èƒ½æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥åˆ‡ç‰‡æ˜¯å¦å®Œæˆ
    clips_dir = Path('./data/clips')
    if not clips_dir.exists():
        print("âŒ æ•°æ®åˆ‡ç‰‡ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ‡ç‰‡è„šæœ¬")
        sys.exit(1)
    
    # ç»Ÿè®¡åˆ‡ç‰‡æƒ…å†µ
    total_clips = 0
    for class_dir in clips_dir.iterdir():
        if class_dir.is_dir():
            count = len(list(class_dir.glob('*.wav')))
            total_clips += count
            print(f"ğŸ“ {class_dir.name}: {count} ä¸ªç‰‡æ®µ")
    
    print(f"ğŸ“Š æ€»è®¡: {total_clips} ä¸ªè®­ç»ƒç‰‡æ®µ")
    
    if total_clips == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒç‰‡æ®µ")
        sys.exit(1)
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    dataset = test_data_loading_speed()
    
    print("\nâœ… ä¼˜åŒ–å®Œæˆï¼ç°åœ¨å¯ä»¥å¿«é€Ÿè®­ç»ƒäº†")
    print("\nğŸ¯ å»ºè®®çš„è®­ç»ƒå‘½ä»¤:")
    print("python train.py --data ./data/clips --batch-size 32 --epochs 10")
    print("\né¢„æœŸè®­ç»ƒé€Ÿåº¦: å‡ ç§’/epochï¼ˆè€Œä¸æ˜¯å‡ åˆ†é’Ÿï¼‰")